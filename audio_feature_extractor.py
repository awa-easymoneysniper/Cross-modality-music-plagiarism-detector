# -*- coding: utf-8 -*-
"""Audio Feature Extractor.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zcAck8oqE6T3MvsufpYPHjP9vpiUO7_0
"""

! pip install openl3

import os
from google.colab import drive
import librosa
import soundfile as sf
import numpy as np
import openl3
import json
from tqdm import tqdm

drive.mount('/content/drive')

import kagglehub

# Download latest version
path = kagglehub.dataset_download("imsparsh/musicnet-dataset")

print("Path to dataset files:", path)

wav_dir = os.path.join(path, "musicnet")
print("WAV目录:", wav_dir)

OUTPUT_EMBEDDING_DIR = "/content/drive/MyDrive/MuseGuard/musicnet_embeddings"
METADATA_DIR = "/content/drive/MyDrive/MuseGuard/musicnet_metadata"

os.makedirs(OUTPUT_EMBEDDING_DIR, exist_ok=True)
os.makedirs(METADATA_DIR, exist_ok=True)

model = openl3.models.load_audio_embedding_model(
    input_repr="mel256",
    content_type="music",
    embedding_size=6144
)

def segment_audio(audio, sr, segment_length=10.0, stride=5.0):
    # 切音频，10s一段，5秒overlap
    segments = []
    metadata = []
    # 存分段和描述信息
    total_duration = len(audio) / sr
    start = 0.0
    segment_id = 0
    while start < total_duration:
        end = start + segment_length
        start_sample = int(start * sr)
        end_sample = int(end * sr)
        if end_sample > len(audio):
            segment = np.pad(audio[start_sample:], (0, end_sample - len(audio)))
            is_padded = True
        # 处理音频结尾分段超过整首歌长度
        else:
            segment = audio[start_sample:end_sample]
            is_padded = False
        segments.append(segment)
        # 加入分段
        metadata.append({
            "segment_id": segment_id,
            "start_time": float(start),
            "end_time": float(min(end, total_duration)),
            "duration": segment_length,
            "is_padded": is_padded,
            "overlap_previous": start > 0,
            "overlap_next": (end < total_duration),
        })
        # 加入分段信息
        start += stride
        segment_id += 1
    return segments, metadata

for root, dirs, files in os.walk(wav_dir):
    for fname in tqdm(files, desc=f"正在处理目录 {root}"):
        if fname.endswith(".wav"):
            wav_path = os.path.join(root, fname)
            recording_id = os.path.splitext(fname)[0]
            audio, sr = librosa.load(wav_path, sr=48000)
            # 调整采样率

            segments, seg_metadata = segment_audio(audio, sr)
            # 拆成10s一段

            with open(os.path.join(METADATA_DIR, f"{recording_id}_metadata.json"), "w") as f:
                json.dump(seg_metadata, f, indent=2)
            # 存分段信息

            for seg_id, segment in enumerate(segments):
                # 遍历，提取embedding
                emb, _ = openl3.get_audio_embedding(
                    segment,
                    sr,
                    model=model,
                    center=False,
                    hop_size=1.0,
                    verbose=False
                )
                aggregated_emb = np.mean(emb, axis=0)
                # 把每秒1个的10个向量合成一个
                np.save(
                    os.path.join(OUTPUT_EMBEDDING_DIR, f"{recording_id}_seg{seg_id}.npy"),
                    aggregated_emb
                )
                # 存数据
